////
Licensed to the Apache Software Foundation (ASF) under one
or more contributor license agreements.  See the NOTICE file
distributed with this work for additional information
regarding copyright ownership.  The ASF licenses this file
to you under the Apache License, Version 2.0 (the
"License"); you may not use this file except in compliance
with the License.  You may obtain a copy of the License at
  http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing,
software distributed under the License is distributed on an
"AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, either express or implied.  See the License for the
specific language governing permissions and limitations
under the License.
////
[[MetadataInjection]]
:imagesdir: ../assets/images
:description: Metadata injection inserts data from various sources into a template pipeline at runtime to reduce repetitive tasks.

= Metadata Injection

Metadata injection inserts data from various sources into a template pipeline at runtime to reduce repetitive tasks.

For example, you might have a simple pipeline to load transaction data values from a supplier, filter specific values, and output them to a file.
If you have more than one supplier, you would need to run this simple pipeline for each supplier.
Yet, with metadata injection, you can expand this simple repetitive pipeline by inserting metadata from another pipeline that contains the ETL Metadata Injection transform.
This transform coordinates the data values from the various inputs through the metadata you define.
This process reduces the need for you to adjust and run the repetitive pipeline for each specific input.

The repetitive pipeline is known as the template pipeline.
The template pipeline is called by the ETL Metadata Injection transform.
You will create a pipeline to prepare what common values you want to use as metadata and inject these specific values through the ETL Metadata Injection transform.

We recommend the following basic procedure for using this transform to inject metadata:

1. Optimize your data for injection, such as preparing folder structures and inputs.

2. Develop pipelines for the repetitive process (the template pipeline), for metadata injection through the ETL Metadata Injection transform, and for handling multiple inputs.

The metadata is injected into the template pipeline through any transform that supports metadata injection.

== Supported Transforms

The goal is to add Metadata Injection support to all transforms, The current (15-October 2022) status is:

|===
|Transform|Supports MDI
|Mapping Output|N
|Memory group by|Y
|Merge join|Y
|Merge rows (diff)|Y
|Metadata Input|Y
|Metadata structure of stream|Y
|Microsoft Access output|Y
|Microsoft Excel input|Y
|Microsoft Excel writer|Y
|MonetDB bulk loader|Y
|MongoDB Delete|Y
|MongoDB input|Y
|MongoDB output|Y
|Multiway merge join|Y
|Neo4j Cypher|Y
|Neo4j Cypher Builder|Y
|Neo4j Generate CSVs|N
|Neo4j Graph Output|Y
|Neo4j Import|Y
|Neo4J Output|Y
|Neo4j Split Graph|N
|Null if|Y
|Number range|Y
|Parquet File Input|Y
|Parquet File Output |Y
|PGP decrypt stream|N
|PGP encrypt stream|N
|Pipeline executor|N
|Pipeline Logging|Y
|Pipeline Probe|Y
|PostgreSQL Bulk Loader|Y
|Process files|Y
|Properties input|N
|Properties output|N
|Regex evaluation|N
|Replace in string|Y
|Reservoir sampling|N
|REST client|N
|Row denormaliser|Y
|Row flattener|N
|Row normaliser|Y
|Rules accumulator|Y
|Rules executor|Y
|Run SSH commands|Y
|Salesforce delete|N
|Salesforce input|Y
|Salesforce insert|N
|Salesforce update|N
|Salesforce upsert|N
|Sample rows|N
|SAS Input|N
|Select values|Y
|Serialize to file|N
|Set field value|Y
|Set field value to a constant|Y
|Set files in result|N
|Set variables|N
|Simple Mapping|N
|Snowflake Bulk Loader|Y
|Sort rows|Y
|Sorted merge|Y
|Split field to rows|Y
|Split fields|Y
|Splunk Input|Y
|SQL file output|N
|SSTable output|Y
|Standardize phone number|Y
|Stream lookup|Y
|Stream Schema Merge|N
|String operations|Y
|Strings cut|Y
|Switch / case|Y
|Synchronize after merge|Y
|Table compare|Y
|Table exists|Y
|Table input|Y
|Table output|Y
|Teradata Fastload bulk loader|N
|Text file input|Y
|Text file input (deprecated)|N
|Text file output|Y
|Token Replacement|Y
|Unique rows|Y
|Unique rows (HashSet)|N
|Update|Y
|User defined Java class|Y
|User defined Java expression|Y
|Value mapper|Y
|Web services lookup|N
|Workflow executor|N
|Workflow Logging|Y
|Write to log|N
|XML input stream (StAX)|N
|XML join|Y
|XML output|Y
|XSD validator|N
|XSL Transformation|N
|YAML input |N
|Zip file|Y
|===
